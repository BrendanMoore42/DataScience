{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Basic Operations on Images\n",
    "\n",
    "Source: https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_core/py_basic_ops/py_basic_ops.html#basic-ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing and Modifying pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('Data/messi1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access a pixel value by its row and column coordinates. For BGR image, it returns an array of Blue, Green, Red values. For grayscale image, just corresponding intensity is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57 63 68]\n"
     ]
    }
   ],
   "source": [
    "px = img[100,100]\n",
    "print(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "# accessing only blue pixel\n",
    "blue = img[100,100,0]\n",
    "print(blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "img[100,100] = [255,255,255]\n",
    "print(img[100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing RED value\n",
    "img.item(10,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify RED values\n",
    "img.itemset((10,10,2), 100)\n",
    "img.item(10,10,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Image Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 450, 3)\n"
     ]
    }
   ],
   "source": [
    "print (img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print (img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image ROI\n",
    "Sometimes, you will have to play with certain region of images. For eye detection in images, first face detection is done all over the image and when face is obtained, we select the face region alone and search for eyes inside it instead of searching whole image. It improves accuracy (because eyes are always on faces :D ) and performance (because we search for a small area)\n",
    "\n",
    "ROI is again obtained using Numpy indexing. Here I am selecting the ball and copying it to another region in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0,60,3) into shape (7,60,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-283adb1d5cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mball\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m280\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m340\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m330\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m390\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m273\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m333\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mball\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (0,60,3) into shape (7,60,3)"
     ]
    }
   ],
   "source": [
    "ball = img[280:340, 330:390]\n",
    "img[273:333, 100:160] = ball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting and Merging Image Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b,g,r = cv2.split(img)\n",
    "#img = cv2.merge(b,g,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = img[:,:,0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img[:,:,2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Borders as Images (Padding)\n",
    "\n",
    "If you want to create a border around the image, something like a photo frame, you can use cv2.copyMakeBorder() function. But it has more applications for convolution operation, zero padding etc. This function takes following arguments:\n",
    "\n",
    "- src - input image\n",
    "\n",
    "- top, bottom, left, right - border width in number of pixels in corresponding directions\n",
    "\n",
    "- borderType - Flag defining what kind of border to be added. It can be following types:\n",
    "    - cv2.BORDER_CONSTANT - Adds a constant colored border. The value should be given as next argument.\n",
    "    - cv2.BORDER_REFLECT - Border will be mirror reflection of the border elements, like this : fedcba|abcdefgh|hgfedcb\n",
    "    - cv2.BORDER_REFLECT_101 or cv2.BORDER_DEFAULT - Same as above, but with a slight change, like this : gfedcb|abcdefgh|gfedcba\n",
    "    - cv2.BORDER_REPLICATE - Last element is replicated throughout, like this: aaaaaa|abcdefgh|hhhhhhh\n",
    "    - cv2.BORDER_WRAP - Canâ€™t explain, it will look like this : cdefgh|abcdefgh|abcdefg\n",
    "- value - Color of border if border type is cv2.BORDER_CONSTANT\n",
    "\n",
    "Below is a sample code demonstrating all these border types for better understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "BLUE = [255,0,0]\n",
    "\n",
    "img1 = cv2.imread('opencv_logo.png')\n",
    "\n",
    "replicate = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REPLICATE)\n",
    "reflect = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT)\n",
    "reflect101 = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT_101)\n",
    "wrap = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_WRAP)\n",
    "constant= cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_CONSTANT,value=BLUE)\n",
    "\n",
    "plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')\n",
    "plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')\n",
    "plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')\n",
    "plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')\n",
    "plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')\n",
    "plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
