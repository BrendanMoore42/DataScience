{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-1-24172a4f228e>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-24172a4f228e>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    ufo.dropna(how='all', inplace-True).shape # Drop, if all columns in row are NaN\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "# Course  Link: https://www.youtube.com/watch?v=fCMrO_VzeL8&index=16&list=PL5-da3qGB5ICCsgW1MxlZ0Hq8LL5U3u9y\n",
    "# pandas version: 18.0-19.0\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 16: how to handle Missing Values\n",
    "# - NaN is refering to a missing Value..simple\n",
    "\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "\n",
    "ufo.tail()\n",
    "\n",
    "ufo.isnull().tail() # shows T and F statement for each data point\n",
    "\n",
    "ufo.notnull().tail # the opposite results of .isnull()\n",
    "\n",
    "ufo.isnull().sum() # number of missing values for each column\n",
    "\n",
    "pd.Series([True, False, True]).sum()\n",
    "\n",
    "ufo[ufo.City.isnull()] # View the 25 row where city is missing\n",
    "\n",
    "ufo.shape # View shape of dataframe\n",
    "\n",
    "ufo.dropna(how='any', inplace=True).shape # Drop all rows where their is 1 missing value in the row\n",
    "\n",
    "ufo.dropna(how='all', inplace-True).shape # Drop, if all columns in row are NaN\n",
    "\n",
    "ufo.dropna(subset=['City','Shape Reported '], how ='any').shape # Drop row if City or Shape Reported is NaN\n",
    "\n",
    "ufo.dropna(subset=['City','Shape Reported '], how ='all').shape # Drop row if City and Shape Reported is NaN\n",
    "\n",
    "ufo['Shape Reported'].value_counts() # Shows the Frequency of Values in column, Missing values are excluded from value_counts function\n",
    "\n",
    "ufo['Shape Reported'].value_counts(dropna = False) # Shows the Frequency of Values in column including NaN\n",
    "\n",
    "ufo['Shape Reported'].fillna(value='VARIOUS', inplace = True) #Fill all Nan values with Various Dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 19 When do I use the inlace parameter\n",
    "\n",
    "ufo.shape\n",
    "\n",
    "ufo.head()\n",
    "\n",
    "ufo.drop(['City'],axis = 1, inplace = True).head() #Drop column inplace\n",
    "\n",
    "ufo.dropna(how='any').shape #Viewing change, that 2490 rows would be dropped\n",
    "\n",
    "ufo.dropna(how='any', inplace = True).shape #drop 2490 rows with NaN values\n",
    "\n",
    "ufo.set_index('Time', inplace = True) #Set Time column as index via inplace\n",
    "\n",
    "ufo = ufo.set_index('Time') #Set Time columns as index via assignment (2nd copy created)\n",
    "\n",
    "#ufo.fillna(method='bfill').tail()\n",
    "\n",
    "#ufo.fillna(method='ffill').tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 22 How to I use pandas with scikit-learn to create Kaggle Submissions?\n",
    "\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "\n",
    "train.head()\n",
    "\n",
    "feature_cols = ['Pclass','Parch']\n",
    "\n",
    "X = train.loc[:, feature_cols]\n",
    "\n",
    "X.shape\n",
    "\n",
    "y = train.Survived\n",
    "\n",
    "y.shape\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X,y)\n",
    "\n",
    "test = pd.read_csv('http://bit.ly/kaggletest')\n",
    "test.head()\n",
    "\n",
    "X_new = test.loc[:,feature_cols]\n",
    "X_new.shape\n",
    "\n",
    "new_pred_class = logreg.predict(X_new) # Guess: Predicts Value\n",
    "\n",
    "new_pred_class\n",
    "\n",
    "pd.DataFrame({'PassengerId':test.PassengerId},'Survived':new_pred_class).set_index('PassengerId').to_csv('sub.csv') \n",
    "# Create a CSV File fro Sumbission after setting index and creating data frame \n",
    "\n",
    "train.to_pickle('train.pk1') \n",
    "\n",
    "pd.read_pickle('train.pk1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 23 More of your pandas questions answered! \n",
    "\n",
    "# Pandas API Reference lists every function within the framework\n",
    "# Some functinos are muplitple methods (Series, Dataframe, pd, i.e isnull())\n",
    "# loc uses inclusive indexing \n",
    "# iloc uses inclusive indexing on the left, and exclusive on the right\n",
    "# Pandas uses Numpy slicing features\n",
    "ufo.loc[:,'City':'State']\n",
    "\n",
    "# Take a random sample\n",
    "\n",
    "ufo.sample(n=3) # Take a random sample from each time the notebook runs the cell\n",
    "\n",
    "ufo.sample(n=3, random_state=42) # Take a random sample, but hold the results the same when running the cell\n",
    "\n",
    "ufo.sample(frac=.75, random_state=42) # Getting a random sample, hold the results, of 75% of the observation within the data frame\n",
    "\n",
    "# you cannot use n and frac in the sample function at the same time\n",
    "\n",
    "\n",
    "# how to split you data into training and testing -> 75/25 split\n",
    "\n",
    "train = ufo.sample(frac=0.75, random_state = 99)\n",
    "test = ufo.loc[~ufo.index.isin(train.index),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 24 How do I create dummy variable in pandas\n",
    "\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "\n",
    "train.head()\n",
    "\n",
    "train['Sex_male'] = train.Sex.map({'female':0, 'male':1}) # New Column, repalce strings with int representations\n",
    "\n",
    "train.head()\n",
    "\n",
    "pd.get_dummies(train.Sex)\n",
    "\n",
    "# number of categorcial variable is k = 10, your want to use k - 1 = 9 dummy variables\n",
    "\n",
    "pd.get_dummies(train.Sex).iloc[:,1:]\n",
    "\n",
    "pd.get_dummies(train.Sex, prefix='Sex').iloc[:,1:] #Dropping and Replacing row in DataFrame with dummies\n",
    "\n",
    "train.Embarked.value_counts()\n",
    "\n",
    "pd.get_dummies(train.Embarked, prefix = 'Embarked')\n",
    "\n",
    "pd.get_dummies(train.Embarked, prefix = 'Embarked').iloc[:,1:] #Dropping and Replacing row in DataFrame with dummies\n",
    "\n",
    "embarked_dummies = pd.get_dummies(train.Embarked, prefix = 'Embarked').iloc[:,1:] \n",
    "\n",
    "train = pd.concat ([train, embarked_dummies],axis = 1) # Concat dataframes\n",
    "\n",
    "train.head()\n",
    "\n",
    "\n",
    "#Bonus -Passinp dataframe to get_dummies function \n",
    "\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "\n",
    "pd.get_dummies(train, columns=['Sex','Embarked']) # Will change colums to dummies in dataframe\n",
    "\n",
    "pd.get_dummies(train, columns=['Sex','Embarked'], drop_first=True) # Will change colums to dummies in dataframe,and drop orginal columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 25 How do I work with dates and times in pandas.\n",
    "\n",
    "import datetime as dt\n",
    "import matplotlib as plt\n",
    "\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "\n",
    "ufo.head()\n",
    "\n",
    "ufo.dtypes\n",
    "\n",
    "#ufo.Time.str.slice(-5,-5).astype(int).head() #Extract Time from String - Messy\n",
    "\n",
    "ufo['Time'] = pd.to_datetime(ufo.Time) #Convert Column to DateTime\n",
    "\n",
    "# pd.to_dateTime automatically figures out the formate of you datetime\n",
    "\n",
    "ufo.dtypes\n",
    "\n",
    "ufo.Time.dt.weekday # Weekday\n",
    "\n",
    "ufo.Time.dt.dayofyear # Day of Year\n",
    "\n",
    "ufo.Time.dt.hour # Hour\n",
    "\n",
    "ufo.Time.dt.weekday_name.head() # Weekday Name\n",
    "\n",
    "#More opition in API documentation \n",
    "\n",
    "ts = pd.to_datetime('1/1/1999') # Timestamp\n",
    "\n",
    "ufo.loc[ufo.Time <= ts,:].head() # Running comparison with Timestamp value\n",
    "\n",
    "ufo.Time.max() - ufo.Time.min() # You can substract times, this is a time delta object \n",
    "\n",
    "\n",
    "# Bonus - Plotting number of UFO reports per year\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "ufo['Year'] = ufo.Time.dt.year\n",
    "\n",
    "ufo.head()\n",
    "\n",
    "ufo.Year.value_counts() #Sorted by Value Counts\n",
    "\n",
    "ufo.Year.value_counts().sort_index() # Sorted By Year\n",
    "\n",
    "ufo.Year.value_counts().sort_index().plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 26 - How to I find and remove duplicate rows in pandas\n",
    "\n",
    "# read a dataset of movie reviewers (modifying the default parameter values for read_table)\n",
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_table('http://bit.ly/movieusers', sep='|', header=None, names=user_cols, index_col = 'user_id')\n",
    "\n",
    "users.head()\n",
    "\n",
    "users.shape\n",
    "\n",
    "users.zip_code.duplicated() # Duplicate F or T statement, if something above in column already exists\n",
    "\n",
    "users.zip_code.duplicated().sum() # Summed number of duplicates\n",
    "\n",
    "users.duplicated() #True if an entire row is the same as a entire row above\n",
    "\n",
    "users.duplicated().sum() # Summed number of duplicates\n",
    "\n",
    "users.loc[users.duplicated(),:] #Using loc to view rows where the duplicates exist\n",
    "\n",
    "users.loc[users.duplicated(keep='first'),:] # Viewing the \"First\" duplicates in the dataframe\n",
    "\n",
    "users.loc[users.duplicated(keep='last'),:] # Viewing the \"last\" duplicates in the dataframe\n",
    "\n",
    "users.loc[users.duplicated(keep=False),:] # Viewing all duplicates as True, viewing all the pairs\n",
    "\n",
    "users.drop_duplicates(keep='first').shape # Dropped first 7 rows\n",
    "\n",
    "users.drop_duplicates(keep='last').shape # Dropped last 7 rows\n",
    "\n",
    "users.drop_duplicates(keep=False).shape # Dropped all 14 rows\n",
    "\n",
    "users.drop_duplicates(subset=['age','zip_code']).shape #Dropping on duplicates from comparing only age and zipcode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 27 How do I avoid a SettingWithCopyWarning in Pandas\n",
    "\n",
    "movies = pd.read_csv('http://bit.ly/imdbratings')\n",
    "\n",
    "movies.head()\n",
    "\n",
    "movies.content_rating.isnull().sum() # View Null Value Totals\n",
    "\n",
    "movies[movies.content_rating.isnull()] # Viewing Null Value rows using Where\n",
    "\n",
    "movies.content_rating.value_counts() # Viewing Value Counts\n",
    "\n",
    "movies[movies.content_rating == 'NOT RATED'] # Viewing all Rows with Content Rating eqauls \"Not Rated\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "movies[movies.content_rating == 'NOT RATED'].content_rating = np.nan # Overwritting Value on Dataframe Warning\n",
    "\n",
    "movies.content_rating.sum() # You can check that the above line of code did not work\n",
    "\n",
    "movies.loc[movies.content_rating == 'NOT RATED','content_rating'] = np.nan\n",
    "\n",
    "# Funcky - Come back to this Lesson \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 28 - How do I change display option in pandas. \n",
    "\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "\n",
    "# You can find options at Pandas GET Option\n",
    "\n",
    "pd.get_option('display.max_rows') # View the Current Option\n",
    "\n",
    "pd.set_option('display.max_rows', None)# View the All Rows\n",
    "\n",
    "pd.set_option('display.max_rows', 100)# View top 100 Rows\n",
    "\n",
    "drinks\n",
    "\n",
    "pd.reset_option('display.max_rows') # Reset Option to Default\n",
    "\n",
    "drinks\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "drinks\n",
    "\n",
    "# 2nd Example\n",
    "\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "\n",
    "train.head() #Strings in Name Column are Viewed as .....\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000) # View column width up to 1000 characters\n",
    "\n",
    "train.head() \n",
    "\n",
    "pd.get_option('display.precision') # Digit are viewied 6 digits after decimal point\n",
    "\n",
    "pd.set_option('display.precision', 2) # Now only 2 decimal points for Fare, underlining data is not affected\n",
    "\n",
    "train.head() \n",
    "\n",
    "# How to format large number to include commas\n",
    "\n",
    "drinks['x'] = drinks.wine_servings * 1000\n",
    "drinks['y'] = drinks.total_litres_of_pure_alcohol * 1000\n",
    "\n",
    "# Added some large numbers\n",
    "\n",
    "drinks.head()\n",
    "\n",
    "pd.set_option('display.float_format','{:,}'.format) # Added comas to floating point numbers\n",
    "\n",
    "# This does not affect Intergers\n",
    "\n",
    "drinks.head()\n",
    "\n",
    "# Bonus - Viewing Pandas Options Offline\n",
    "\n",
    "pd.describe_option() # Describes Every Option\n",
    "\n",
    "pd.describe_option('row') #Searching Options by Strin \"row\" on Option Title\n",
    "\n",
    "pd.reset_options('all') # Reset All Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 29 - How do I creat a pandas Dataframe from another object\n",
    "\n",
    "# Create Dataframe from Dictionary\n",
    "\n",
    "pd.DataFrame({'id':[100,101,102], 'color':['red','blue','red']}) # Unorder Dataframe\n",
    "\n",
    "pd.DataFrame({'id':[100,101,102], 'color':['red','blue','red']}, columns=['id','color']) # Specified column order\n",
    "\n",
    "df = pd.DataFrame({'id':[100,101,102], 'color':['red','blue','red']}, columns=['id','color'], index=['a','b','c']) #Added index to dataframe\n",
    "\n",
    "# Create Dataframe from Lists\n",
    "\n",
    "pd.DataFrame([[100,'red'],[101,'blue'],[102,'red']]) # List are stacked on top of each other\n",
    "\n",
    "pd.DataFrame([[100,'red'],[101,'blue'],[102,'red']], columns=['id','color']) # Specified Columns\n",
    "\n",
    "\n",
    "# Create Dataframe from Numpy Arrary\n",
    "\n",
    "arr = np.random.rand(4,2) # Generate Random Number via Beta Distribution\n",
    "arr\n",
    "\n",
    "pd.DataFrame(arr) # created Dataframe \n",
    "\n",
    "pd.DataFrame(arr, columns=['one','two']) #specified columns\n",
    "\n",
    "# Create Large DataFrame\n",
    "\n",
    "pd.DataFrame({'student':np.arange(100,110,1), 'test':np.random.randint(60,101,10)}) \n",
    "\n",
    "#np arange (inclusive, exclusive, step)\n",
    "\n",
    "pd.DataFrame({'student':np.arange(100,110,1), 'test':np.random.randint(60,101,10)}).set_index('student') # you can set index when creating dataframe via the function\n",
    "\n",
    "\n",
    "# Bonus\n",
    "\n",
    "s = pd.Series(['round','square'],index=['c','b'], name='shape') #created a series\n",
    "\n",
    "df\n",
    "\n",
    "pd.concat ([df,s],axis=1) # Concat a row , and aliged a the row accordinly to the index. Creating a Nan Value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#30 - How do I apply a function to a pandas Series or Dataframe\n",
    "\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "train.head()\n",
    "\n",
    "# Maps allows you to map a value in a series to another value\n",
    "\n",
    "train['Sex_num'] = train.Sex.map({'female':0,'male':0}) #Translate values to 0 or 1\n",
    "\n",
    "train.loc[0:4, ['Sex', 'Sex_num']]\n",
    "\n",
    "# Apply - Series and DataFrame\n",
    "\n",
    "train['Name_length'] = train.Name.apply(len)\n",
    "\n",
    "train.loc[0:4, ['Name','Name_length']] # Counts the Number of character in strinp\n",
    "\n",
    "train['Fare_ceil'] = train.Fare.apply(np.ceil)\n",
    "\n",
    "train.loc[0:4,['Fare','Fare_ceil']] # Round values up Via Apply\n",
    "\n",
    "train.Name.str.split(',').head() # Spliting String by coma, into a list of string \n",
    "\n",
    "def get_element(my_list, position):\n",
    "    return my_list[position]\n",
    "\n",
    "train.Name.str.split(',').apply(get_element, position = 0).head() # Set and use function that get first strinp from list\n",
    "\n",
    "train.Name.str.split(',').apply(lambda x: x[0]).head() # A 2nd approach using lamda instead of defining function\n",
    "\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "\n",
    "drinks.head()\n",
    "\n",
    "drinks.loc[:,'beer_servings':'wine_servings'].apply(max, axis = 0) # Determing Max value form each Column\n",
    "\n",
    "drinks.loc[:,'beer_servings':'wine_servings'].apply(max, axis = 1)# Determing Max value form each Row\n",
    "\n",
    "drinks.loc[:,'beer_servings':'wine_servings'].apply(np.argmax, axis = 1) # Determining what columns has the highest value for each row\n",
    "\n",
    "\n",
    "# Apply Map - Data Frame, apply to every element in Dataframe\n",
    "\n",
    "drinks.loc[:,'beer_servings':'wine_servings'] = drinks.loc[:,'beer_servings':'wine_servings'].applymap(float)\n",
    "drinks.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
